---
layout: post
title: Social Network Analysis SNL HW 13
subtitle: Using Python 3 to create edges from a dispatch to create a social network graph with Gephi
gh-repo: starlord32/starlord32.github.io
gh-badge: [star, fork, follow]
tags: [historian, python, codecademy, science, SNL, social network analysis, gephi]
comments: true
---

## Script to retrieve dispatch date, article number and place names mentioned in each articles

```
from bs4 import BeautifulSoup
import re
import os

newPathToFolder = "D:/Users/MarkDaniel/My Documents/Masterstudium_Geschichte_Backup/DigitalHumanities/DH-Tools_and_Techniques/lesson13/"
pathToFolder = "D:/Users/MarkDaniel/My Documents/Masterstudium_Geschichte_Backup/DigitalHumanities/DH-Tools_and_Techniques/lesson11/4th/"
listOfFiles = os.listdir(pathToFolder)
dicFreq = {}
placeNames = []
resultsCSV = []


# for loop that opens all files of a defined folder and stores it with BeautifulSoup in variable soup
for f in listOfFiles:
    soup = BeautifulSoup (open(pathToFolder+f, "r", encoding="utf8"), features="lxml")
    # searches for list items of "date" and return maximum two elemens
    issue_date = soup.find_all("date", limit=2)[1] # only returns the second match
    issue_date = issue_date.get("value")
    # searches for all tags with "div3" and stores it in variable "articles"
    articles = soup.find_all("div3", type = True)
                                                                                # counter to count each article
    counter = 0

    for a in articles:
        counter += 1                                                            # for loop that counts each article
        places = a.find_all("placename", key = True)                            # continues to find all placenames with an attribute
        article = issue_date + "-article-" + str(counter)                       # variable that holds the issue date of the dispatch a string and an article counter
        print(article)
        for p in places:
            place = p.get_text()                                                # for loop to retrieve all placenames as value from the placename tag
            key = p["key"].split(";")                                           # variable that holds the tgn number
            print(str(place) + "-" + str(key))

            for k in key:
                key = [d for d in k if d.isdigit()]                             # for loop to clean tgn numbers digits only
                tag_id = ''.join(key)

                placeList = "\t".join([article,place,tag_id])                   # creating a variable that holds each result article, place, tag_id
                placeNames.append(placeList)                                    # appending the variable to a list

for i in placeNames:                                                            # creating a frequency with a for loop for all place names
    if i in dicFreq:
        dicFreq[i] += 1
    else:
        dicFreq[i]  = 1

for key, value in dicFreq.items():                                              # removes all placenames that are mention once only
    if value > 1: # this will exclude items with frequency 1
        newVal = "%09d\t%s" % (value, key)
        # newVal will looks like: `000005486 TAB Richmond`
        resultsCSV.append(newVal)

resultsCSV = sorted(resultsCSV, reverse=True)                                   # sorting the results variable
print(len(resultsCSV)) # will print out the number of items in the list
resultsToSave = "\n".join(resultsCSV)                                           # joining the results line by line

# creates a new file in a target folder with name + article counter + name + issue_date + txt file
newfile = newPathToFolder  + "resultsFull_3.csv"

# creating a header for the final file
header = "id\ttarget\tsource\ttgn\n"

# saving
with open(newfile, "w", encoding="utf8") as f8:
    f8.write(header+"".join(resultsToSave))
```

## Result: Network Edges List usable for Gephi

Total of : 47,429 entries

Important Note: The script above does not include place names that are mentioned once only.
I created an edges list that also includes place names mentioned once but the list is not workable for Gephi because the network gets to dense.

![ResultsForGephi](/img/resultsFull_03.png)

## Gephi SNL Graphs

*1:*

Zoom into the connected network:
The cities that are connected the most to articles are: Richmond, Virginia, Washington, "Confederate States", "United States", "England", North Carolina, ...
The articles which are connected the most to cities are: article-99, article-9, article-96, article-97, ...
Clusters: The above mentioned cities, states and articles also form various clusters. Richmond, Virginia and Whashington seem to be the most relevant.

![GephiGraph](/img/final1.1.png)

*2:*

The original picture without zoom shows thousands of cities, states and articles that are not connected at all according to Gephi.

![GephiGraph](/img/final1.2.png)
